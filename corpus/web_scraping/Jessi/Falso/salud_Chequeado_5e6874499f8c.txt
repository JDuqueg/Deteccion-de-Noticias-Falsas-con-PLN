{
  "id": "5e6874499f8c",
  "label": 0,
  "title": "No, el video de Mario Lugones diciendo \"no gestiono emociones, gestiono números\" no es real: está hecho con inteligencia artificial - Chequeado",
  "description": "En las últimas semanas, en el contexto del conflicto del Hospital Garrahan, se viralizó un video donde Mario Lugones, ministro de Salud de la Nación, dice: \"No gestiono emociones, gestiono...",
  "body": "En las últimas semanas, en el contexto del conflicto del Hospital Garrahan , se viralizó un video donde Mario Lugones, ministro de Salud de la Nación, dice: “No gestiono emociones, gestiono números”. Sin embargo, este video es falso: el ministro nunca dijo públicamente esa frase, y además la imagen fue generada mediante inteligencia artificial (IA). El video se compartió en X , Instagram y Facebook , alcanzando más de 8 mil reacciones y 50 mil reproducciones. Ante la consulta de Chequeado , desde el área de prensa del ministro de Salud indicaron que “el video es falso”, y agregaron que consideran que se trata de IA, “ya que la voz parece de alguien de 30 años”. En el video que se viralizó, la imagen modificada del ministro empieza diciendo: “Soy Mario Lugones, soy el ministro de Salud de la Nación argentina, y no gestiono emociones, gestiono números”. “No se trata de cuántos médicos se queden con sueldos miserables ni de cuántos niños mueran esperando atención. El déficit fiscal no se negocia”, agrega la voz del video. Sin embargo, no hay registros ni en Google ni en las redes sociales del Lugone s o del ministerio de Salud donde se encuentre que pronunció esas frases. La imagen de fondo del video coincide con la de su presentación en el evento AmCham Summit 2025, que se desarrolló en mayo. Sin embargo, en ningún momento del evento pronuncia esas palabras. Según expertos en detección de contenidos manipulados, como los del MIT Media Lab , los videos creados con IA suelen presentar detalles que los observadores atentos pueden notar. El video analizado presenta indicios claros de haber sido generado con inteligencia artificial, en particular mediante técnicas de lip syncing , donde la voz se superpone sobre una animación artificial del rostro. Una señal clave es que los movimientos de los labios no se corresponden de forma natural con el audio: las palabras se pronuncian, pero la boca no se mueve con la sincronía ni fluidez propias de una persona hablando realmente. Tal como advierte el proyecto Detect DeepFakes, desarrollado por el MIT Media Lab, “algunos deepfakes se basan en la sincronización labial. ¿Los movimientos de los labios parecen naturales?”, y en este caso, la respuesta es negativa. Además, no existe un único signo inequívoco que delate este tipo de manipulaciones: los contenidos creados con IA suelen mostrar una combinación de pequeñas anomalías que, vistas en conjunto, permiten sospechar de su veracidad. Como señala el mismo proyecto del MIT, “cuando se trata de medios manipulados con IA, no hay una única señal infalible para detectar un video falso. Sin embargo, hay varios indicios típicos de deepfakes que conviene observar”. En este video, además del desfase entre la voz y la boca, también se observa un movimiento lento y antinatural de las manos, lo que refuerza la hipótesis de que se trata de una producción artificial. Además, la voz del ministro en el video tiene una tonalidad extraña, que no coincide con sus discursos o entrevistas previas ni con su estilo habitual. Como se explicó en esta nota , para identificar un video generado con inteligencia artificial, es importante prestar atención a los detalles. Los videos generados por IA suelen tener pequeños errores o inconsistencias, como una mirada fija, movimientos lentos o poco naturales. Si encontrás un video que te genera dudas, un buen primer paso es buscar la fuente original. Si no la encontrás, es probable que sea falso. También es fundamental analizar el ecosistema digital, observando las cuentas que están difundiendo el video, sus intenciones y si repiten mensajes similares. Y finalmente, es importante desconfiar de los videos que apelan fuertemente a las emociones, ya que este tipo de contenidos suele ser manipulado para generar una reacción inmediata. Este chequeo es parte de la iniciativa Third Party Fact-checking de Meta en la Argentina. Valoramos mucho la opinión de nuestra comunidad de lectores y siempre estamos a favor del debate y del intercambio. Por eso es importante para nosotros generar un espacio de respeto y cuidado, por lo que por favor tené en cuenta que no publicaremos comentarios con insultos, agresiones o mensajes de odio, desinformaciones que pudieran resultar peligrosas para otros, información personal, o promoción o venta de productos. Muchas gracias Tu dirección de correo electrónico no será publicada. Los campos obligatorios están marcados con * Comentario * Nombre * Correo electrónico * Web Δ",
  "url": "https://chequeado.com/ultimas-noticias/no-el-video-de-mario-lugones-diciendo-no-gestiono-emociones-gestiono-numeros-no-es-real-esta-hecho-con-inteligencia-artificial/"
}